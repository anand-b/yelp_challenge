{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Clustering Businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1310 unique categories and subcategories for all businesses\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "\n",
    "business_csv_file = open(os.path.join(\"..\",\"data\",\"biz_csv\",\"business.csv\"),\"r\")\n",
    "business_csv = csv.reader(business_csv_file)\n",
    "\n",
    "categories = list()\n",
    "for line in business_csv:\n",
    "    categories.append(line[-1])\n",
    "categories = categories[1:]\n",
    "\n",
    "business_csv_file.close()\n",
    "\n",
    "unique_cats = set()\n",
    "for category in categories:\n",
    "    cat_list = re.split(\",|&\",category)\n",
    "    for cat in cat_list:\n",
    "        cat = cat.lower().strip()\n",
    "        if len(cat) > 0:\n",
    "            unique_cats.add(cat.lower().strip())\n",
    "\n",
    "print(\"There are \"+str(len(unique_cats))+\" unique categories and subcategories for all businesses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import csv\n",
    "import pandas\n",
    "\n",
    "\n",
    "# business_csv_file = open(os.path.join(\"..\",\"data\",\"biz_csv\",\"business.csv\"),\"r\")\n",
    "# business_csv = csv.reader(business_csv_file)\n",
    "\n",
    "def cluster_by_category(data, n_clusters):\n",
    "    categories = list()\n",
    "    for line in data:\n",
    "        categories.append(line[-1])\n",
    "        \n",
    "    vectorizer = TfidfVectorizer(stop_words='english') #,token_pattern='[a-zA-Z0-9\\s&]+' # term-frequency x inverse-document frequency\n",
    "    # tokenize based on comma instead of space. Otherwise, words like \"Public Services\" will not be seen as a single word \n",
    "    # by the vectorizer\n",
    "    cat = vectorizer.fit_transform(categories)\n",
    "\n",
    "    kmeans_model = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=100, n_init=1,random_state=1)\n",
    "    kmeans_model.fit(cat)\n",
    "\n",
    "    business_csv_clustered_file = open(os.path.join(\"..\",\"data\",\"biz_csv\",\"business_clustered.csv\"),\"a+\")\n",
    "    business_clustered_csv = csv.writer(business_csv_clustered_file)\n",
    "\n",
    "    for line in data:\n",
    "        if not (line[-1] == \"categories\"):\n",
    "            line.extend(kmeans_model.predict(vectorizer.transform(line[-1:])))\n",
    "            business_clustered_csv.writerow(line)\n",
    "\n",
    "    business_csv_clustered_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import csv\n",
    "import pandas\n",
    "\n",
    "def cluster_by_position_and_category(n_clusters):\n",
    "    business_csv_file = open(os.path.join(\"..\",\"data\",\"biz_csv\",\"business.csv\"),\"r\")\n",
    "    business_csv = csv.reader(business_csv_file)\n",
    "\n",
    "    categories = list()\n",
    "    first_line = 1;\n",
    "    for line in business_csv:\n",
    "        if first_line > 1:\n",
    "            categories.append([float(line[1]), float(line[2])])\n",
    "        else:\n",
    "            categories.append([line[1], line[2]])\n",
    "        first_line += 1\n",
    "    categories = categories[1:]\n",
    "\n",
    "    kmeans_model = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=100, n_init=1,random_state=1)\n",
    "    kmeans_model.fit(categories)\n",
    "\n",
    "    business_csv_file.close()\n",
    "\n",
    "    business_csv_file = open(os.path.join(\"..\",\"data\",\"biz_csv\",\"business.csv\"),\"r\")\n",
    "    business_csv = csv.reader(business_csv_file)\n",
    "\n",
    "    cluster_buckets = dict()\n",
    "\n",
    "    for line in business_csv:\n",
    "        if not (line[-1] == \"categories\"):\n",
    "            pred = kmeans_model.predict([[line[1],line[2]]])[0]\n",
    "            if not pred in cluster_buckets: \n",
    "                cluster_buckets[pred] = list()\n",
    "            cluster_buckets[pred].append(line)\n",
    "\n",
    "    business_csv_file.close()\n",
    "    for cluster in cluster_buckets:\n",
    "        print(\"Processing cluster number \"+str(cluster))\n",
    "        cluster_by_category(cluster_buckets[cluster], n_clusters=min(len(cluster_buckets[cluster]),n_clusters))\n",
    "\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "cluster_by_position_and_category(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
