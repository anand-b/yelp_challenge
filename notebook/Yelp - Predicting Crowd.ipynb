{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Clustering Businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1310 unique categories and subcategories for all businesses\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "\n",
    "business_csv_file = open(os.path.join(\"..\",\"data\",\"biz_csv\",\"business.csv\"),\"r\", encoding='utf-8')\n",
    "business_csv = csv.reader(business_csv_file)\n",
    "\n",
    "categories = list()\n",
    "for line in business_csv:\n",
    "    #print(line)\n",
    "    categories.append(line[-1])\n",
    "categories = categories[1:]\n",
    "\n",
    "business_csv_file.close()\n",
    "\n",
    "unique_cats = set()\n",
    "for category in categories:\n",
    "    cat_list = re.split(\",|&\",category)\n",
    "    for cat in cat_list:\n",
    "        cat = cat.lower().strip()\n",
    "        if len(cat) > 0:\n",
    "            unique_cats.add(cat.lower().strip())\n",
    "\n",
    "print(\"There are \"+str(len(unique_cats))+\" unique categories and subcategories for all businesses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import csv\n",
    "import pandas\n",
    "\n",
    "\n",
    "# business_csv_file = open(os.path.join(\"..\",\"data\",\"biz_csv\",\"business.csv\"),\"r\", encoding=\"utf8\")\n",
    "# business_csv = csv.reader(business_csv_file)\n",
    "\n",
    "def cluster_by_category(data, n_clusters):\n",
    "    categories = list()\n",
    "    for line in data:\n",
    "        categories.append(line[-1])\n",
    "        \n",
    "    vectorizer = TfidfVectorizer(stop_words='english') #,token_pattern='[a-zA-Z0-9\\s&]+' # term-frequency x inverse-document frequency\n",
    "    # tokenize based on comma instead of space. Otherwise, words like \"Public Services\" will not be seen as a single word \n",
    "    # by the vectorizer\n",
    "    cat = vectorizer.fit_transform(categories)\n",
    "\n",
    "    kmeans_model = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=100, n_init=1,random_state=1)\n",
    "    kmeans_model.fit(cat)\n",
    "\n",
    "    business_csv_clustered_file = open(os.path.join(\"..\",\"data\",\"biz_csv\",\"business_clustered.csv\"),\"a+\", newline='')\n",
    "    business_clustered_csv = csv.writer(business_csv_clustered_file)\n",
    "\n",
    "    for line in data:\n",
    "        if not (line[-1] == \"categories\"):\n",
    "            line.extend(kmeans_model.predict(vectorizer.transform(line[-1:])))\n",
    "            business_clustered_csv.writerow(line)\n",
    "\n",
    "    business_csv_clustered_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import csv\n",
    "import pandas\n",
    "\n",
    "def cluster_by_position_and_category(n_clusters):\n",
    "    business_csv_file = open(os.path.join(\"..\",\"data\",\"biz_csv\",\"business.csv\"),\"r\", encoding=\"utf8\")\n",
    "    business_csv = csv.reader(business_csv_file)\n",
    "\n",
    "    categories = list()\n",
    "    first_line = 1;\n",
    "    for line in business_csv:\n",
    "        if first_line > 1:\n",
    "            categories.append([float(line[1]), float(line[2])])\n",
    "        else:\n",
    "            categories.append([line[1], line[2]])\n",
    "        first_line += 1\n",
    "    categories = categories[1:]\n",
    "\n",
    "    kmeans_model = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=100, n_init=1,random_state=1)\n",
    "    kmeans_model.fit(categories)\n",
    "\n",
    "    business_csv_file.close()\n",
    "\n",
    "    business_csv_file = open(os.path.join(\"..\",\"data\",\"biz_csv\",\"business.csv\"),\"r\", encoding=\"utf8\")\n",
    "    business_csv = csv.reader(business_csv_file)\n",
    "\n",
    "    cluster_buckets = dict()\n",
    "\n",
    "    for line in business_csv:\n",
    "        if not (line[-1] == \"categories\"):\n",
    "            pred = kmeans_model.predict([[line[1],line[2]]])[0]\n",
    "            if not pred in cluster_buckets: \n",
    "                cluster_buckets[pred] = list()\n",
    "            cluster_buckets[pred].append(line)\n",
    "\n",
    "    business_csv_file.close()\n",
    "    for cluster in cluster_buckets:\n",
    "        print(\"Processing cluster number \"+str(cluster))\n",
    "        cluster_by_category(cluster_buckets[cluster], n_clusters=min(len(cluster_buckets[cluster]),n_clusters))\n",
    "\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cluster number 16\n",
      "Processing cluster number 6\n",
      "Processing cluster number 5\n",
      "Processing cluster number 4\n",
      "Processing cluster number 10\n",
      "Processing cluster number 19\n",
      "Processing cluster number 17\n",
      "Processing cluster number 1\n",
      "Processing cluster number 2\n",
      "Processing cluster number 8\n",
      "Processing cluster number 7\n",
      "Processing cluster number 11\n",
      "Processing cluster number 3\n",
      "Processing cluster number 0\n",
      "Processing cluster number 15\n",
      "Processing cluster number 9\n",
      "Processing cluster number 18\n",
      "Processing cluster number 12\n",
      "Processing cluster number 13\n",
      "Processing cluster number 14\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "cluster_by_position_and_category(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cross-validation 50-25-25 over this business.csv (cluster only 50% data)\n",
    "#do the regression, training the check-in data over 50% data. --> in RAM! \n",
    "#for each validation data, we will find the cluster and then filter businesses fromm the same cluster\n",
    "#take check-in data for those check-in businesses and learn to predict the crowd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
