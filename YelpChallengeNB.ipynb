{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Yelp NLP\n",
    "\n",
    "##Phase I - Pre-processing the data:\n",
    "\n",
    "###Objectives in this phase:\n",
    "The main objective of this phase is **exploratory data analysis**. We do that by analysing each attribute and,\n",
    "1. Look at the distribution (in case of numerical attribute)\n",
    "2. Standardize the data (in case of numerical attribute)\n",
    "3. Convert categorical data to numerical data\n",
    "4. Identify the output variable(s)\n",
    "5. Feature Engineering (removing redundant data features, finding dependent features)\n",
    "    - PCA - finding independent and uncorrelated features that have significant variance\n",
    "    - summarizing or clustering data with not much variance\n",
    "6. Visualizing the data\n",
    "    - histograms\n",
    "    - scatter plot of output vs each attribute\n",
    "7. Identify the features among the attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Splitting the dataset into small chunks:\n",
    "First, we split the large dataset into small chunks as separate files. Primarily, user.json and review.json are huge files that requires a lot of RAM. Splitting the files enables us to load one fold at a time, thereby, reducing the load on memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "#setting up path to dataset\n",
    "user_json = os.path.join(\"..\",\"data\",\"user.json\")\n",
    "user_data_dir = os.path.join(\"..\",\"data\",\"user\")\n",
    "review_json = os.path.join(\"..\",\"data\",\"review.json\")\n",
    "review_data_dir = os.path.join(\"..\",\"data\",\"review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting review json to chunks of csv files...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def convert_review_to_csv(json_file_path, out_dir, lines_per_file):\n",
    "    columns = ['user_id','business_id','text','stars','useful','funny','cool']\n",
    "    json_file = open(json_file_path, 'r')\n",
    "    count = 0\n",
    "    fname = 1\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    output = csv.writer(open(os.path.join(out_dir,str(fname)+\".csv\"), \"w+\"))\n",
    "    output.writerow(columns)\n",
    "    for line in json_file:\n",
    "        count += 1\n",
    "        j = json.loads(line)\n",
    "        j['text'] = j['text'].replace(\"\\n\",\" \")\n",
    "        csv_arr = list()\n",
    "        for column in columns:\n",
    "            if column in j:\n",
    "                csv_arr.append(j[column])\n",
    "        output.writerow(csv_arr)\n",
    "        if count == lines_per_file:\n",
    "            count = 0\n",
    "            fname += 1\n",
    "            output = csv.writer(open(os.path.join(out_dir,str(fname)+\".csv\"), \"w+\"))\n",
    "    json_file.close()\n",
    "    \n",
    "print(\"Converting review json to chunks of csv files...\")\n",
    "review_json = os.path.join(\"..\",\"data\",\"review.json\")\n",
    "review_csv_dir = os.path.join(\"..\",\"data\",\"review_csv\")\n",
    "convert_review_to_csv(json_file_path=review_json, out_dir=review_csv_dir, lines_per_file=50000)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting user json to chunks of csv files...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def convert_user_to_csv(json_file_path, out_dir, lines_per_file):\n",
    "    columns = ['user_id', 'name', 'review_count', 'yelping_since', 'useful', 'funny', 'cool', \n",
    "               'fans', 'elite', 'average_stars', 'compliment_hot', 'compliment_more', 'compliment_profile', \n",
    "               'compliment_cute', 'compliment_list', 'compliment_note', 'compliment_plain', 'compliment_cool', \n",
    "               'compliment_funny', 'compliment_writer', 'compliment_photos']\n",
    "    json_file = open(json_file_path, 'r')\n",
    "    count = 0\n",
    "    fname = 1\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    output = csv.writer(open(os.path.join(out_dir,str(fname)+\".csv\"), \"w+\"))\n",
    "    output.writerow(columns)\n",
    "    for line in json_file:\n",
    "        count += 1\n",
    "        j = json.loads(line)\n",
    "        csv_arr = list()\n",
    "        for column in columns:\n",
    "            if column in j:\n",
    "                csv_arr.append(j[column])\n",
    "        output.writerow(csv_arr)\n",
    "        if count == lines_per_file:\n",
    "            count = 0\n",
    "            fname += 1\n",
    "            output = csv.writer(open(os.path.join(out_dir,str(fname)+\".csv\"), \"w+\"))\n",
    "    json_file.close()\n",
    "    \n",
    "print(\"Converting user json to chunks of csv files...\")\n",
    "user_json = os.path.join(\"..\",\"data\",\"user.json\")\n",
    "user_csv_dir = os.path.join(\"..\",\"data\",\"user_csv\")\n",
    "convert_user_to_csv(json_file_path=user_json, out_dir=user_csv_dir, lines_per_file=50000)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting business json to chunks of csv files...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def convert_business_to_csv(json_file_path, out_dir, lines_per_file):\n",
    "    columns = ['business_id','name','address','city','state','postal_code','latitude','longitude','stars']\n",
    "    json_file = open(json_file_path, 'r')\n",
    "    count = 0\n",
    "    fname = 1\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    output = csv.writer(open(os.path.join(out_dir,str(fname)+\".csv\"), \"w+\"))\n",
    "    output.writerow(columns)\n",
    "    for line in json_file:\n",
    "        count += 1\n",
    "        j = json.loads(line)\n",
    "        csv_arr = list()\n",
    "        for column in columns:\n",
    "            if column in j:\n",
    "                csv_arr.append(j[column])\n",
    "        output.writerow(csv_arr)\n",
    "        if count == lines_per_file:\n",
    "            count = 0\n",
    "#             output.close()\n",
    "            fname += 1\n",
    "            output = csv.writer(open(os.path.join(out_dir,str(fname)+\".csv\"), \"w+\"))\n",
    "#     output.close()\n",
    "    json_file.close()\n",
    "    \n",
    "print(\"Converting business json to chunks of csv files...\")\n",
    "biz_json = os.path.join(\"..\",\"data\",\"business.json\")\n",
    "biz_csv_dir = os.path.join(\"..\",\"data\",\"biz_csv\")\n",
    "convert_business_to_csv(json_file_path=biz_json, out_dir=biz_csv_dir, lines_per_file=50000)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of review.json :\n",
      "Total number of records: 4736897\n",
      "Attributes:  ['review_id', 'user_id', 'business_id', 'stars', 'date', 'text', 'useful', 'funny', 'cool']\n",
      "\n",
      "Summary of user.json :\n",
      "Total number of records: 1183362\n",
      "Attributes:  ['user_id', 'name', 'review_count', 'yelping_since', 'friends', 'useful', 'funny', 'cool', 'fans', 'elite', 'average_stars', 'compliment_hot', 'compliment_more', 'compliment_profile', 'compliment_cute', 'compliment_list', 'compliment_note', 'compliment_plain', 'compliment_cool', 'compliment_funny', 'compliment_writer', 'compliment_photos']\n",
      "\n",
      "Summary of business.json :\n",
      "Total number of records: 156639\n",
      "Attributes:  ['business_id', 'name', 'neighborhood', 'address', 'city', 'state', 'postal_code', 'latitude', 'longitude', 'stars', 'review_count', 'is_open', 'attributes', 'categories', 'hours']\n"
     ]
    }
   ],
   "source": [
    "#utility to get a summary of the dataset...\n",
    "import os\n",
    "import json \n",
    "\n",
    "def get_summary(file_path):\n",
    "    file = open(file_path, 'r')\n",
    "    line = json.loads(file.readline())\n",
    "    attributes = list(line.keys())\n",
    "    count = 1\n",
    "    for line in file:\n",
    "        count+=1\n",
    "    file.close()\n",
    "\n",
    "    return (count,attributes)\n",
    "\n",
    "summary = get_summary(os.path.join(\"..\",\"data\",\"review.json\"))\n",
    "print(\"Summary of review.json :\")\n",
    "print(\"Total number of records: \"+str(summary[0]))\n",
    "print(\"Attributes: \",summary[1])\n",
    "\n",
    "summary = get_summary(os.path.join(\"..\",\"data\",\"user.json\"))\n",
    "print(\"\\nSummary of user.json :\")\n",
    "print(\"Total number of records: \"+str(summary[0]))\n",
    "print(\"Attributes: \",summary[1])\n",
    "\n",
    "summary = get_summary(os.path.join(\"..\",\"data\",\"business.json\"))\n",
    "print(\"\\nSummary of business.json :\")\n",
    "print(\"Total number of records: \"+str(summary[0]))\n",
    "print(\"Attributes: \",summary[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
